{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computer vision - Laboratory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "==============================================================================================\n",
    "## Practicum 3: Image and Video Segmentation\n",
    "\n",
    "=============================================================================================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main topics are:\n",
    "\n",
    "1)\tSegmentation of video shots with static scenes.\n",
    "\n",
    "2) Background substraction.\n",
    "\n",
    "3)\tSegmentation of images.\n",
    "\n",
    "In order to successfuly complete this practicum it is necessary to understand the following theory concepts: background substraction, K-means clustering, etc.\n",
    "\n",
    "The following chapters of the book “Computer Vision: Algorithms and Applicatons” from Richard Szeliski have further information about the topic:\n",
    "\n",
    "* Chapter 4: Computer Vision: Algorithms and Applications.\n",
    "\n",
    "* Chapter 5: Segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Background substraction methods\n",
    "\n",
    "\n",
    "Given the video stored in ‘Barcelona-sequence’, which contains images acquired by a static camera, remove all the \"artifacts\" considered as foreground related to movement extracting the background images.\n",
    "\n",
    "Note: One of the applications of these methods is the button \"remove tourists\" implemented in most commercial photo cameras. For instance, Adobe uses the \"Monument Mode\", which automatically deletes the people going by the cameras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and visualize the sequence of images \"images/Barcelona-sequence\"\n",
    "Hint: In order to read a  collection of images, we wil use the function animation.FuncAnimation [https://matplotlib.org/2.0.0/api/_as_gen/matplotlib.animation.FuncAnimation.html].\n",
    "\n",
    "Observe in the following example, how FuncAnimation is used to read and visualize a sequence of frames. Explore the parameters of animation.FuncAnimation()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ic = io.ImageCollection('images/Barcelona-sequence/*.png')\n",
    "        # Reading a sequence of images from a folder\n",
    "\n",
    "import matplotlib.animation as animation\n",
    "%matplotlib nbagg \n",
    "    #Changing the pluggin is necessary always when visualizing a video!\n",
    "\n",
    "i=0       #Inicializing the video display\n",
    "fig = plt.figure()  # Create figure\n",
    "im = plt.imshow(ic[i], animated=True) #Visualize the first image\n",
    "\n",
    "def updatefig1(i):   #Updating the frame visualization\n",
    "    im.set_array(ic[i*5]) #Changing the content of the canvas\n",
    "    return im, #to return a tuple!\n",
    "\n",
    "ani = animation.FuncAnimation(fig, updatefig1, interval=5, blit=False, frames=50, repeat= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Find where a shot (scene) finishes and the following starts (boundaries). Each of the scenes in a video is usually called 'shot'. Which measure can be used in order to visually distinguish the shots in a plot? Explain your solution.\n",
    "\n",
    "Show the initial and final images of each shot extracted as follows:\n",
    "\n",
    "<img src=\"images_for_notebook/result_shot_detection.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hint:** take the following example of video and temporal plot visualization as a template. The plot must be replaced by a frame by frame measure to be defined by you, being applicable to distinguish the shots.\n",
    "\n",
    "- If you need to convert the image to float, the command is: img_as_float()\n",
    "- If you need the histogram, it is in skimage.exposure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example\n",
    "# Sinusoidal plot points generation\n",
    "def data_gen():\n",
    "    t = data_gen.t\n",
    "    cnt = 0\n",
    "    while cnt < 1000:\n",
    "        cnt+=1\n",
    "        t += 0.05\n",
    "        y = np.cos(2*np.pi*t) * np.exp(-t/10.)\n",
    "        # adapted the data generator to yield both sin and cos\n",
    "        yield t, y\n",
    "\n",
    "data_gen.t = 0\n",
    "\n",
    "%matplotlib nbagg\n",
    "\n",
    "# create a figure with two subplots\n",
    "fig, (ax1, ax2) = plt.subplots(2,1)\n",
    "\n",
    "# intialize a line object on the second axes for plotting\n",
    "line, = ax2.plot([], [], lw=2, color='r')\n",
    "\n",
    "ax2.set_ylim(-1.1, 1.1)\n",
    "ax2.set_xlim(0, 5)\n",
    "ax2.grid()\n",
    "\n",
    "# initialize the data arrays \n",
    "xdata, ydata = [], []\n",
    "def run(data):\n",
    "    # update the data plot\n",
    "    t, y = data\n",
    "    xdata.append(t) # time = x axis\n",
    "    ydata.append(y) # y axis\n",
    "\n",
    "    # Plot image on top row\n",
    "    ax1.imshow(ic[len(xdata)])\n",
    "          \n",
    "    # Plot sin in bottom row\n",
    "    xmin, xmax = ax2.get_xlim()\n",
    "    if t >= xmax:\n",
    "        ax2.set_xlim(xmin, 2*xmax)\n",
    "        ax2.figure.canvas.draw()\n",
    "            \n",
    "    # update the data of both line objects\n",
    "    line.set_data(xdata, ydata)\n",
    "\n",
    "    return line\n",
    "\n",
    "ani = animation.FuncAnimation(fig, run, data_gen, blit=True, interval=10, repeat=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Background substraction\n",
    "\n",
    "Apply the background substraction algorithm (check theory material).\n",
    "\n",
    "Visualize, for each shot of the video:\n",
    "    1) images belonging to the shot\n",
    "    2) the background image, and\n",
    "    3) the foreground.\n",
    "    \n",
    "**Hint**: You can construct a mask obtained from the original image and the background in order to know which parts of the image form part from the foreground and recover from the original image just the foreground regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment your implementation including details. What happens if the shots are not correctly extracted? What happens if you find too many shots in the video? What do the static background images represent? In which situations does the algorithm work and in which it does not? What happens if you substract the background image from the original one?\n",
    "\n",
    "Do you see any additional application for this algorithm?\n",
    "\n",
    "**[OPTIONAL]**\n",
    "Apply the algorithm to some other static video that you found."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.3 Clustering methods on the RGB-XY space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Read any image from the folder 'images' and segment it using Felzenszwalbs's method. Test different parameters in order to obtain a good image segmentation. How does each parameter behave? Which are the optimal values? Comment what algorithm is the method based in up to 3 lines most.\n",
    "\n",
    "**Hint**: \n",
    "- Different image segmentation commands can be found in skimage.segmentation.\n",
    "- Use the function segmentation.mark_boundaries for seeing the boundaries of the segments.\n",
    "- Use the inline pluggin to visualize images (%matplotlib inline)\n",
    "- Add title to the figures to explain what is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Segment the previous image using SLIC algorithm. Test different parameters in order to obtain a good image segmentation. How does each parameter behave? Upt o your opinion, which are the optimal values? Comment what algorithm is the method based in up to 3 lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Plot the original image and the results of both algorithms in a 1x3 subplot. Calculate also the number of segments obtained on the image by each of the algorithms. Comment the differences between each method as well as their advantages and disadvantages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
